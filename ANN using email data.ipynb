{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the raw data\n",
    "#remove punctuations from data\n",
    "#remove punctuations from data\n",
    "#remove stopwords from data\n",
    "#Handle Tokenization\n",
    " #apply lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('English')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam=pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\SpamData.tsv \",delimiter=\"\\t\")\n",
    "spam.columns=['labels','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               text\n",
       "0   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "2    ham  Even my brother is not like to speak with me. ...\n",
       "3    ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "4    ham  As per your request 'Melle Melle (Oru Minnamin..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")) ,3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=spam.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               text  len  punct%\n",
       "0   spam  Free entry in 2 a wkly comp to win FA Cup fina...  128     4.7\n",
       "1    ham  Nah I don't think he goes to usf, he lives aro...   49     4.1\n",
       "2    ham  Even my brother is not like to speak with me. ...   62     3.2\n",
       "3    ham                I HAVE A DATE ON SUNDAY WITH WILL!!   28     7.1\n",
       "4    ham  As per your request 'Melle Melle (Oru Minnamin...  135     4.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam['len'] = spam['text'].apply(lambda x:len(x) - x.count(\" \"))\n",
    "spam['punct%'] = spam['text'].apply(lambda x:count_punct(x))\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+',text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "       \"Nah I don't think he goes to usf, he lives around here though\",\n",
       "       'Even my brother is not like to speak with me. They treat me like aids patent.',\n",
       "       ..., 'Pity, * was in mood for that. So...any other suggestions?',\n",
       "       \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\",\n",
       "       'Rofl. Its true to its name'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bag of words#\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_features=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=cv.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '06',\n",
       " '0800',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '0870',\n",
       " '08712460324',\n",
       " '08718720201',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10am',\n",
       " '10p',\n",
       " '11',\n",
       " '11mths',\n",
       " '12',\n",
       " '12hrs',\n",
       " '1327',\n",
       " '150',\n",
       " '150p',\n",
       " '150ppm',\n",
       " '16',\n",
       " '18',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '20p',\n",
       " '25',\n",
       " '250',\n",
       " '25p',\n",
       " '2day',\n",
       " '2lands',\n",
       " '2nd',\n",
       " '2nite',\n",
       " '30',\n",
       " '3030',\n",
       " '350',\n",
       " '36504',\n",
       " '3g',\n",
       " '400',\n",
       " '4u',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50p',\n",
       " '5wb',\n",
       " '5we',\n",
       " '62468',\n",
       " '750',\n",
       " '7pm',\n",
       " '800',\n",
       " '8007',\n",
       " '82277',\n",
       " '85023',\n",
       " '86688',\n",
       " '87066',\n",
       " '87077',\n",
       " '8th',\n",
       " '900',\n",
       " 'abiola',\n",
       " 'able',\n",
       " 'about',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'account',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'address',\n",
       " 'admirer',\n",
       " 'advance',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'age16',\n",
       " 'ago',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'aight',\n",
       " 'al',\n",
       " 'alex',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alrite',\n",
       " 'also',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angry',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'apartment',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'ar',\n",
       " 'ard',\n",
       " 'are',\n",
       " 'area',\n",
       " 'around',\n",
       " 'arrive',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ass',\n",
       " 'at',\n",
       " 'attempt',\n",
       " 'auction',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'await',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'b4',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bak',\n",
       " 'balance',\n",
       " 'bank',\n",
       " 'bath',\n",
       " 'bathe',\n",
       " 'battery',\n",
       " 'bb',\n",
       " 'bcoz',\n",
       " 'be',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'been',\n",
       " 'before',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'biz',\n",
       " 'black',\n",
       " 'blood',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'body',\n",
       " 'bold',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'bored',\n",
       " 'boss',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'boytoy',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'brings',\n",
       " 'brother',\n",
       " 'bslvyl',\n",
       " 'bt',\n",
       " 'bucks',\n",
       " 'budget',\n",
       " 'bugis',\n",
       " 'bus',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'bx420',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'call',\n",
       " 'call2optout',\n",
       " 'called',\n",
       " 'caller',\n",
       " 'callertune',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'camcorder',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'campus',\n",
       " 'can',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'cant',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carlos',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'catch',\n",
       " 'cause',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'cell',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charity',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'checking',\n",
       " 'cheers',\n",
       " 'chennai',\n",
       " 'chikku',\n",
       " 'children',\n",
       " 'choose',\n",
       " 'christmas',\n",
       " 'cinema',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'click',\n",
       " 'close',\n",
       " 'club',\n",
       " 'co',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'colleagues',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'colour',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comin',\n",
       " 'coming',\n",
       " 'comp',\n",
       " 'company',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complimentary',\n",
       " 'computer',\n",
       " 'comuk',\n",
       " 'confirm',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'convey',\n",
       " 'cool',\n",
       " 'copy',\n",
       " 'correct',\n",
       " 'cos',\n",
       " 'cost',\n",
       " 'costa',\n",
       " 'could',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'coz',\n",
       " 'cr9',\n",
       " 'crave',\n",
       " 'crazy',\n",
       " 'credit',\n",
       " 'credits',\n",
       " 'croydon',\n",
       " 'cs',\n",
       " 'cum',\n",
       " 'cup',\n",
       " 'currently',\n",
       " 'custcare',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cuz',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'damn',\n",
       " 'darlin',\n",
       " 'darren',\n",
       " 'dat',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'day',\n",
       " 'days',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decimal',\n",
       " 'deep',\n",
       " 'definitely',\n",
       " 'del',\n",
       " 'delivery',\n",
       " 'den',\n",
       " 'depends',\n",
       " 'details',\n",
       " 'dey',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'digital',\n",
       " 'din',\n",
       " 'dinner',\n",
       " 'dint',\n",
       " 'direct',\n",
       " 'dis',\n",
       " 'discount',\n",
       " 'disturb',\n",
       " 'dnt',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'dogging',\n",
       " 'doin',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'double',\n",
       " 'down',\n",
       " 'download',\n",
       " 'draw',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'drugs',\n",
       " 'dude',\n",
       " 'dun',\n",
       " 'dunno',\n",
       " 'during',\n",
       " 'dvd',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eatin',\n",
       " 'eating',\n",
       " 'eg',\n",
       " 'eh',\n",
       " 'either',\n",
       " 'else',\n",
       " 'em',\n",
       " 'email',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'energy',\n",
       " 'england',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entered',\n",
       " 'entitled',\n",
       " 'entry',\n",
       " 'especially',\n",
       " 'etc',\n",
       " 'eve',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'ex',\n",
       " 'exam',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excuse',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'expires',\n",
       " 'extra',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fact',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'fancy',\n",
       " 'fantasies',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fault',\n",
       " 'fb',\n",
       " 'feb',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'figure',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'fingers',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'first',\n",
       " 'five',\n",
       " 'fixed',\n",
       " 'flag',\n",
       " 'flirt',\n",
       " 'flower',\n",
       " 'following',\n",
       " 'fone',\n",
       " 'food',\n",
       " 'for',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'forward',\n",
       " 'forwarded',\n",
       " 'found',\n",
       " 'fr',\n",
       " 'free',\n",
       " 'freemsg',\n",
       " 'freephone',\n",
       " 'frens',\n",
       " 'fri',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'frm',\n",
       " 'frnd',\n",
       " 'frnds',\n",
       " 'from',\n",
       " 'fuck',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fullonsms',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'future',\n",
       " 'gal',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gas',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'gd',\n",
       " 'ge',\n",
       " 'gee',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'gettin',\n",
       " 'getting',\n",
       " 'getzed',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'girlfrnd',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'gn',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodmorning',\n",
       " 'goodnight',\n",
       " 'got',\n",
       " 'goto',\n",
       " 'gotta',\n",
       " 'gr8',\n",
       " 'great',\n",
       " 'green',\n",
       " 'grins',\n",
       " 'group',\n",
       " 'gt',\n",
       " 'guaranteed',\n",
       " 'gud',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'haf',\n",
       " 'haha',\n",
       " 'hai',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'hav',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heavy',\n",
       " 'hee',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hey',\n",
       " 'hg',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'him',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hiya',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hmv',\n",
       " 'ho',\n",
       " 'hold',\n",
       " 'holding',\n",
       " 'holiday',\n",
       " 'holla',\n",
       " 'home',\n",
       " 'honey',\n",
       " 'hop',\n",
       " 'hope',\n",
       " 'hoping',\n",
       " 'horny',\n",
       " 'hospital',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hows',\n",
       " 'howz',\n",
       " 'hr',\n",
       " 'hrs',\n",
       " 'http',\n",
       " 'huh',\n",
       " 'hungry',\n",
       " 'hunny',\n",
       " 'hurry',\n",
       " 'hurt',\n",
       " 'hurts',\n",
       " 'hw',\n",
       " 'iam',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'identifier',\n",
       " 'if',\n",
       " 'il',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'imagine',\n",
       " 'imma',\n",
       " 'immediately',\n",
       " 'important',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'including',\n",
       " 'india',\n",
       " 'indian',\n",
       " 'info',\n",
       " 'information',\n",
       " 'informed',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'insurance',\n",
       " 'interested',\n",
       " 'internet',\n",
       " 'into',\n",
       " 'invited',\n",
       " 'inviting',\n",
       " 'ip4',\n",
       " 'ipod',\n",
       " 'is',\n",
       " 'ish',\n",
       " 'isn',\n",
       " 'isnt',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'ive',\n",
       " 'izzit',\n",
       " 'january',\n",
       " 'jay',\n",
       " 'job',\n",
       " 'john',\n",
       " 'join',\n",
       " 'joined',\n",
       " 'joke',\n",
       " 'joy',\n",
       " 'jus',\n",
       " 'just',\n",
       " 'juz',\n",
       " 'kallis',\n",
       " 'kano',\n",
       " 'kate',\n",
       " 'kb',\n",
       " 'keep',\n",
       " 'keeping',\n",
       " 'kept',\n",
       " 'kerala',\n",
       " 'kick',\n",
       " 'kids',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'king',\n",
       " 'kiss',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'knw',\n",
       " 'land',\n",
       " 'landline',\n",
       " 'laptop',\n",
       " 'lar',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'laugh',\n",
       " 'lazy',\n",
       " 'ldew',\n",
       " 'ldn',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'leaving',\n",
       " 'lect',\n",
       " 'left',\n",
       " 'leh',\n",
       " 'lei',\n",
       " 'lemme',\n",
       " 'less',\n",
       " 'lesson',\n",
       " 'lessons',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'liao',\n",
       " 'library',\n",
       " 'life',\n",
       " 'lift',\n",
       " 'light',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'link',\n",
       " 'list',\n",
       " 'listen',\n",
       " 'little',\n",
       " 'live',\n",
       " 'll',\n",
       " 'lmao',\n",
       " 'loads',\n",
       " 'loan',\n",
       " 'log',\n",
       " 'login',\n",
       " 'logo',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lor',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'lovable',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'lovely',\n",
       " 'lover',\n",
       " 'loves',\n",
       " 'loving',\n",
       " 'loyalty',\n",
       " 'lt',\n",
       " 'ltd',\n",
       " 'luck',\n",
       " 'lucky',\n",
       " 'lunch',\n",
       " 'luv',\n",
       " 'made',\n",
       " 'mah',\n",
       " 'maid',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'malaria',\n",
       " 'man',\n",
       " 'many',\n",
       " 'march',\n",
       " 'mark',\n",
       " 'marriage',\n",
       " 'married',\n",
       " 'match',\n",
       " 'matches',\n",
       " 'mate',\n",
       " 'mates',\n",
       " 'maximize',\n",
       " 'may',\n",
       " 'mayb',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meaning',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'medical',\n",
       " 'meds',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'meh',\n",
       " 'melle',\n",
       " 'member',\n",
       " 'men',\n",
       " 'menu',\n",
       " 'merry',\n",
       " 'message',\n",
       " 'messages',\n",
       " 'met',\n",
       " 'mid',\n",
       " 'midnight',\n",
       " 'might',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'mins',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'miracle',\n",
       " 'miss',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'mistake',\n",
       " 'mm',\n",
       " 'mo',\n",
       " 'moan',\n",
       " 'mob',\n",
       " 'mobile',\n",
       " 'mobiles',\n",
       " 'mobileupd8',\n",
       " 'mode',\n",
       " 'model',\n",
       " 'mom',\n",
       " 'moment',\n",
       " 'mon',\n",
       " 'monday',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'mood',\n",
       " 'moon',\n",
       " 'moral',\n",
       " 'more',\n",
       " 'morning',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'motorola',\n",
       " 'move',\n",
       " 'movie',\n",
       " 'movies',\n",
       " 'mp3',\n",
       " 'mr',\n",
       " 'mrng',\n",
       " 'mrt',\n",
       " 'msg',\n",
       " 'msgs',\n",
       " 'mu',\n",
       " 'much',\n",
       " 'mum',\n",
       " 'murdered',\n",
       " 'murderer',\n",
       " 'music',\n",
       " 'must',\n",
       " 'muz',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'na',\n",
       " 'nah',\n",
       " 'naked',\n",
       " 'name',\n",
       " 'national',\n",
       " 'naughty',\n",
       " 'near',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'net',\n",
       " 'network',\n",
       " 'neva',\n",
       " 'never',\n",
       " 'new',\n",
       " 'news',\n",
       " 'next',\n",
       " 'ni8',\n",
       " 'nice',\n",
       " 'nigeria',\n",
       " 'night',\n",
       " 'nite',\n",
       " 'no',\n",
       " 'no1',\n",
       " 'nobody',\n",
       " 'noe',\n",
       " 'nokia',\n",
       " 'none',\n",
       " 'noon',\n",
       " 'nope',\n",
       " 'normal',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'notice',\n",
       " 'now',\n",
       " 'nt',\n",
       " 'ntt',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'nxt',\n",
       " 'nyt',\n",
       " 'o2',\n",
       " 'of',\n",
       " 'off',\n",
       " 'offer',\n",
       " 'offers',\n",
       " 'office',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'okie',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'omw',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'online',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'oops',\n",
       " 'open',\n",
       " 'operator',\n",
       " 'opinion',\n",
       " 'opt',\n",
       " 'or',\n",
       " 'orange',\n",
       " 'orchard',\n",
       " 'order',\n",
       " 'oredi',\n",
       " 'oso',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'own',\n",
       " 'pa',\n",
       " 'page',\n",
       " 'paid',\n",
       " 'pain',\n",
       " 'paper',\n",
       " 'parents',\n",
       " 'park',\n",
       " 'part',\n",
       " 'partner',\n",
       " 'party',\n",
       " 'pass',\n",
       " 'password',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'pc',\n",
       " 'people',\n",
       " 'per',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'persons',\n",
       " 'pete',\n",
       " 'phone',\n",
       " 'phones',\n",
       " 'photo',\n",
       " 'pic',\n",
       " 'pick',\n",
       " 'picked',\n",
       " 'picking',\n",
       " 'pics',\n",
       " 'pilates',\n",
       " 'pin',\n",
       " 'pix',\n",
       " 'pizza',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'planned',\n",
       " 'planning',\n",
       " 'plans',\n",
       " 'play',\n",
       " 'player',\n",
       " 'players',\n",
       " 'please',\n",
       " 'pleased',\n",
       " 'pleasure',\n",
       " 'plenty',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'plz',\n",
       " 'pm',\n",
       " 'po',\n",
       " 'pobox',\n",
       " 'pobox334',\n",
       " 'pobox84',\n",
       " 'point',\n",
       " 'points',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>06</th>\n",
       "      <th>0800</th>\n",
       "      <th>08000839402</th>\n",
       "      <th>08000930705</th>\n",
       "      <th>0870</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yup</th>\n",
       "      <th>zed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5567 rows Ã— 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  02  03  04  06  0800  08000839402  08000930705  0870  ...  yo  \\\n",
       "0      0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "1      0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "2      0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "3      0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "4      0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "...   ..  ...  ..  ..  ..  ..   ...          ...          ...   ...  ...  ..   \n",
       "5562   0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "5563   0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "5564   0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "5565   0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "5566   0    0   0   0   0   0     0            0            0     0  ...   0   \n",
       "\n",
       "      yoga  you  your  yours  yourself  yr  yrs  yup  zed  \n",
       "0        0    0     0      0         0   0    0    0    0  \n",
       "1        0    0     0      0         0   0    0    0    0  \n",
       "2        0    0     0      0         0   0    0    0    0  \n",
       "3        0    0     0      0         0   0    0    0    0  \n",
       "4        0    0     3      0         0   0    0    0    0  \n",
       "...    ...  ...   ...    ...       ...  ..  ...  ...  ...  \n",
       "5562     0    0     0      0         0   0    0    0    0  \n",
       "5563     0    0     0      0         0   0    0    0    0  \n",
       "5564     0    0     0      0         0   0    0    0    0  \n",
       "5565     0    0     0      0         0   0    0    0    0  \n",
       "5566     0    0     0      0         0   0    0    0    0  \n",
       "\n",
       "[5567 rows x 1500 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x,columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate TFIDF(converting data into vector format to apply ML or DL\n",
    "#consider TFIDF as new dataset\n",
    "#consider the input variable(TFIDF) and output variable from Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec=TfidfVectorizer(max_features=1510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfidf=tfidf_vec.fit_transform(spam['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '06',\n",
       " '0800',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '0870',\n",
       " '08712460324',\n",
       " '08718720201',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10am',\n",
       " '10p',\n",
       " '11',\n",
       " '11mths',\n",
       " '12',\n",
       " '12hrs',\n",
       " '1327',\n",
       " '150',\n",
       " '150p',\n",
       " '150ppm',\n",
       " '16',\n",
       " '18',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '20p',\n",
       " '25',\n",
       " '250',\n",
       " '25p',\n",
       " '2day',\n",
       " '2lands',\n",
       " '2nd',\n",
       " '2nite',\n",
       " '30',\n",
       " '3030',\n",
       " '350',\n",
       " '36504',\n",
       " '3g',\n",
       " '400',\n",
       " '4u',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50p',\n",
       " '5wb',\n",
       " '5we',\n",
       " '62468',\n",
       " '750',\n",
       " '7pm',\n",
       " '800',\n",
       " '8007',\n",
       " '82277',\n",
       " '85023',\n",
       " '86688',\n",
       " '87066',\n",
       " '87077',\n",
       " '8th',\n",
       " '900',\n",
       " 'abiola',\n",
       " 'able',\n",
       " 'about',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'account',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'address',\n",
       " 'admirer',\n",
       " 'advance',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'age16',\n",
       " 'ago',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'aight',\n",
       " 'al',\n",
       " 'alex',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alrite',\n",
       " 'also',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angry',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'apartment',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'ar',\n",
       " 'ard',\n",
       " 'are',\n",
       " 'area',\n",
       " 'around',\n",
       " 'arrive',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ass',\n",
       " 'at',\n",
       " 'attempt',\n",
       " 'auction',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'await',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'b4',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bak',\n",
       " 'balance',\n",
       " 'bank',\n",
       " 'bath',\n",
       " 'bathe',\n",
       " 'battery',\n",
       " 'bb',\n",
       " 'bcoz',\n",
       " 'be',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'been',\n",
       " 'before',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'biz',\n",
       " 'black',\n",
       " 'blood',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'body',\n",
       " 'bold',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'bored',\n",
       " 'boss',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'boytoy',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'brings',\n",
       " 'brother',\n",
       " 'bslvyl',\n",
       " 'bt',\n",
       " 'bucks',\n",
       " 'budget',\n",
       " 'bugis',\n",
       " 'bus',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'bx420',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'call',\n",
       " 'call2optout',\n",
       " 'called',\n",
       " 'caller',\n",
       " 'callertune',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'camcorder',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'campus',\n",
       " 'can',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'cant',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carlos',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'catch',\n",
       " 'cause',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'cell',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charity',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'checking',\n",
       " 'cheers',\n",
       " 'chennai',\n",
       " 'chikku',\n",
       " 'children',\n",
       " 'choose',\n",
       " 'christmas',\n",
       " 'cinema',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'click',\n",
       " 'close',\n",
       " 'club',\n",
       " 'co',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'colleagues',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'colour',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comin',\n",
       " 'coming',\n",
       " 'comp',\n",
       " 'company',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complimentary',\n",
       " 'computer',\n",
       " 'comuk',\n",
       " 'confirm',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'convey',\n",
       " 'cool',\n",
       " 'copy',\n",
       " 'correct',\n",
       " 'cos',\n",
       " 'cost',\n",
       " 'costa',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'coz',\n",
       " 'cr9',\n",
       " 'crave',\n",
       " 'crazy',\n",
       " 'credit',\n",
       " 'credits',\n",
       " 'croydon',\n",
       " 'cs',\n",
       " 'cum',\n",
       " 'cup',\n",
       " 'currently',\n",
       " 'custcare',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cuz',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'damn',\n",
       " 'darlin',\n",
       " 'darren',\n",
       " 'dat',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'day',\n",
       " 'days',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decimal',\n",
       " 'deep',\n",
       " 'definitely',\n",
       " 'del',\n",
       " 'delivery',\n",
       " 'den',\n",
       " 'depends',\n",
       " 'details',\n",
       " 'dey',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'digital',\n",
       " 'din',\n",
       " 'dinner',\n",
       " 'dint',\n",
       " 'direct',\n",
       " 'dis',\n",
       " 'discount',\n",
       " 'disturb',\n",
       " 'dnt',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'dogging',\n",
       " 'doin',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'double',\n",
       " 'down',\n",
       " 'download',\n",
       " 'draw',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'drugs',\n",
       " 'dude',\n",
       " 'dun',\n",
       " 'dunno',\n",
       " 'during',\n",
       " 'dvd',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eatin',\n",
       " 'eating',\n",
       " 'eg',\n",
       " 'eh',\n",
       " 'either',\n",
       " 'else',\n",
       " 'em',\n",
       " 'email',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'energy',\n",
       " 'england',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entered',\n",
       " 'entitled',\n",
       " 'entry',\n",
       " 'especially',\n",
       " 'etc',\n",
       " 'eve',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'ex',\n",
       " 'exam',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exciting',\n",
       " 'excuse',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'expires',\n",
       " 'extra',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fact',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'fancy',\n",
       " 'fantasies',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fault',\n",
       " 'fb',\n",
       " 'feb',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'felt',\n",
       " 'fetch',\n",
       " 'few',\n",
       " 'fight',\n",
       " 'figure',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'fingers',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'first',\n",
       " 'five',\n",
       " 'fixed',\n",
       " 'flag',\n",
       " 'flirt',\n",
       " 'flower',\n",
       " 'following',\n",
       " 'fone',\n",
       " 'food',\n",
       " 'for',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'forward',\n",
       " 'forwarded',\n",
       " 'found',\n",
       " 'fr',\n",
       " 'free',\n",
       " 'freemsg',\n",
       " 'freephone',\n",
       " 'frens',\n",
       " 'fri',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'frm',\n",
       " 'frnd',\n",
       " 'frnds',\n",
       " 'from',\n",
       " 'fuck',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fullonsms',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'future',\n",
       " 'gal',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gas',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'gd',\n",
       " 'ge',\n",
       " 'gee',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'gettin',\n",
       " 'getting',\n",
       " 'getzed',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'girlfrnd',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'gn',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodmorning',\n",
       " 'goodnight',\n",
       " 'got',\n",
       " 'goto',\n",
       " 'gotta',\n",
       " 'gr8',\n",
       " 'great',\n",
       " 'green',\n",
       " 'grins',\n",
       " 'group',\n",
       " 'gt',\n",
       " 'guaranteed',\n",
       " 'gud',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'haf',\n",
       " 'haha',\n",
       " 'hai',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'hav',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heavy',\n",
       " 'hee',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hey',\n",
       " 'hg',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'him',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hiya',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hmv',\n",
       " 'ho',\n",
       " 'hold',\n",
       " 'holding',\n",
       " 'holiday',\n",
       " 'holla',\n",
       " 'home',\n",
       " 'honey',\n",
       " 'hop',\n",
       " 'hope',\n",
       " 'hoping',\n",
       " 'horny',\n",
       " 'hospital',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hows',\n",
       " 'howz',\n",
       " 'hr',\n",
       " 'hrs',\n",
       " 'http',\n",
       " 'huh',\n",
       " 'hungry',\n",
       " 'hunny',\n",
       " 'hurry',\n",
       " 'hurt',\n",
       " 'hurts',\n",
       " 'hw',\n",
       " 'iam',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'identifier',\n",
       " 'if',\n",
       " 'il',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'imagine',\n",
       " 'imma',\n",
       " 'immediately',\n",
       " 'important',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'including',\n",
       " 'india',\n",
       " 'indian',\n",
       " 'info',\n",
       " 'information',\n",
       " 'informed',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'insurance',\n",
       " 'interested',\n",
       " 'internet',\n",
       " 'into',\n",
       " 'invited',\n",
       " 'inviting',\n",
       " 'ip4',\n",
       " 'ipod',\n",
       " 'is',\n",
       " 'ish',\n",
       " 'isn',\n",
       " 'isnt',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'ive',\n",
       " 'izzit',\n",
       " 'january',\n",
       " 'jay',\n",
       " 'job',\n",
       " 'john',\n",
       " 'join',\n",
       " 'joined',\n",
       " 'joke',\n",
       " 'joy',\n",
       " 'jus',\n",
       " 'just',\n",
       " 'juz',\n",
       " 'kallis',\n",
       " 'kano',\n",
       " 'kate',\n",
       " 'kb',\n",
       " 'keep',\n",
       " 'keeping',\n",
       " 'kept',\n",
       " 'kerala',\n",
       " 'kick',\n",
       " 'kids',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'king',\n",
       " 'kiss',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'knw',\n",
       " 'land',\n",
       " 'landline',\n",
       " 'laptop',\n",
       " 'lar',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'laugh',\n",
       " 'lazy',\n",
       " 'ldew',\n",
       " 'ldn',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'leaving',\n",
       " 'lect',\n",
       " 'left',\n",
       " 'leh',\n",
       " 'lei',\n",
       " 'lemme',\n",
       " 'less',\n",
       " 'lesson',\n",
       " 'lessons',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'liao',\n",
       " 'library',\n",
       " 'life',\n",
       " 'lift',\n",
       " 'light',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'link',\n",
       " 'list',\n",
       " 'listen',\n",
       " 'little',\n",
       " 'live',\n",
       " 'll',\n",
       " 'lmao',\n",
       " 'loads',\n",
       " 'loan',\n",
       " 'log',\n",
       " 'login',\n",
       " 'logo',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lor',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'lovable',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'lovely',\n",
       " 'lover',\n",
       " 'loves',\n",
       " 'loving',\n",
       " 'loyalty',\n",
       " 'lt',\n",
       " 'ltd',\n",
       " 'luck',\n",
       " 'lucky',\n",
       " 'lunch',\n",
       " 'luv',\n",
       " 'made',\n",
       " 'mah',\n",
       " 'maid',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'malaria',\n",
       " 'man',\n",
       " 'many',\n",
       " 'march',\n",
       " 'mark',\n",
       " 'marriage',\n",
       " 'married',\n",
       " 'match',\n",
       " 'matches',\n",
       " 'mate',\n",
       " 'mates',\n",
       " 'maximize',\n",
       " 'may',\n",
       " 'mayb',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meaning',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'medical',\n",
       " 'meds',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'meh',\n",
       " 'melle',\n",
       " 'member',\n",
       " 'men',\n",
       " 'menu',\n",
       " 'merry',\n",
       " 'message',\n",
       " 'messages',\n",
       " 'met',\n",
       " 'mid',\n",
       " 'midnight',\n",
       " 'might',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'mins',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'miracle',\n",
       " 'miss',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'mistake',\n",
       " 'mm',\n",
       " 'mo',\n",
       " 'moan',\n",
       " 'mob',\n",
       " 'mobile',\n",
       " 'mobiles',\n",
       " 'mobileupd8',\n",
       " 'mode',\n",
       " 'model',\n",
       " 'mom',\n",
       " 'moment',\n",
       " 'mon',\n",
       " 'monday',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'mood',\n",
       " 'moon',\n",
       " 'moral',\n",
       " 'more',\n",
       " 'morning',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'motorola',\n",
       " 'move',\n",
       " 'movie',\n",
       " 'movies',\n",
       " 'mp3',\n",
       " 'mr',\n",
       " 'mrng',\n",
       " 'mrt',\n",
       " 'msg',\n",
       " 'msgs',\n",
       " 'mu',\n",
       " 'much',\n",
       " 'mum',\n",
       " 'murdered',\n",
       " 'murderer',\n",
       " 'music',\n",
       " 'must',\n",
       " 'muz',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'na',\n",
       " 'nah',\n",
       " 'naked',\n",
       " 'name',\n",
       " 'national',\n",
       " 'naughty',\n",
       " 'near',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'net',\n",
       " 'network',\n",
       " 'neva',\n",
       " 'never',\n",
       " 'new',\n",
       " 'news',\n",
       " 'next',\n",
       " 'ni8',\n",
       " 'nice',\n",
       " 'nigeria',\n",
       " 'night',\n",
       " 'nite',\n",
       " 'no',\n",
       " 'no1',\n",
       " 'nobody',\n",
       " 'noe',\n",
       " 'nokia',\n",
       " 'none',\n",
       " 'noon',\n",
       " 'nope',\n",
       " 'normal',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'notice',\n",
       " 'now',\n",
       " 'nt',\n",
       " 'ntt',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'nxt',\n",
       " 'nyt',\n",
       " 'o2',\n",
       " 'of',\n",
       " 'off',\n",
       " 'offer',\n",
       " 'offers',\n",
       " 'office',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'okie',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'omw',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'online',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'oops',\n",
       " 'open',\n",
       " 'operator',\n",
       " 'opinion',\n",
       " 'opt',\n",
       " 'or',\n",
       " 'orange',\n",
       " 'orchard',\n",
       " 'order',\n",
       " 'oredi',\n",
       " 'oso',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'own',\n",
       " 'pa',\n",
       " 'page',\n",
       " 'paid',\n",
       " 'pain',\n",
       " 'paper',\n",
       " 'parents',\n",
       " 'park',\n",
       " 'part',\n",
       " 'partner',\n",
       " 'party',\n",
       " 'pass',\n",
       " 'password',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'pc',\n",
       " 'people',\n",
       " 'per',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'persons',\n",
       " 'pete',\n",
       " 'phone',\n",
       " 'phones',\n",
       " 'photo',\n",
       " 'pic',\n",
       " 'pick',\n",
       " 'picked',\n",
       " 'picking',\n",
       " 'pics',\n",
       " 'pilates',\n",
       " 'pin',\n",
       " 'pix',\n",
       " 'pizza',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'planned',\n",
       " 'planning',\n",
       " 'plans',\n",
       " 'play',\n",
       " 'player',\n",
       " 'players',\n",
       " 'please',\n",
       " 'pleased',\n",
       " 'pleasure',\n",
       " 'plenty',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'plz',\n",
       " 'pm',\n",
       " 'po',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>06</th>\n",
       "      <th>0800</th>\n",
       "      <th>08000839402</th>\n",
       "      <th>08000930705</th>\n",
       "      <th>0870</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yup</th>\n",
       "      <th>zed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5567 rows Ã— 1510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000   02   03   04   06  0800  08000839402  08000930705  0870  ...  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "...   ...  ...  ...  ...  ...  ...   ...          ...          ...   ...  ...   \n",
       "5562  0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "5563  0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "5564  0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "5565  0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "5566  0.0  0.0  0.0  0.0  0.0  0.0   0.0          0.0          0.0   0.0  ...   \n",
       "\n",
       "       yo  yoga  you      your  yours  yourself   yr  yrs  yup  zed  \n",
       "0     0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0   0.0  0.0  0.302603    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...   ...  ...       ...    ...       ...  ...  ...  ...  ...  \n",
       "5562  0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "5563  0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "5564  0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "5565  0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "5566  0.0   0.0  0.0  0.000000    0.0       0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5567 rows x 1510 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_tfidf,columns=tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5567, 1510)\n"
     ]
    }
   ],
   "source": [
    "print(x_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-189287a700c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "y=spam['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       128\n",
       "1        49\n",
       "2        62\n",
       "3        28\n",
       "4       135\n",
       "       ... \n",
       "5562    131\n",
       "5563     29\n",
       "5564     48\n",
       "5565    100\n",
       "5566     21\n",
       "Name: len, Length: 5567, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_tfidf,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4453, 1510)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4453,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 1510)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Building the NN model#\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add input layer#\n",
    "x_train.shape[1]\n",
    "model.add(Dense(input_dim = x_train.shape[1],kernel_initializer=\"random_uniform\",activation=\"relu\",units=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add hiddenlayer#\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",activation=\"relu\",units=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add output layer#\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",activation=\"sigmoid\",units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                15110     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 15,183\n",
      "Trainable params: 15,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Compile the model#\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 3s 3ms/step - loss: -7.4522 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: -309.0831 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: -1977.4136 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: -6629.8969 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: -15075.4144 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ef8a1379a0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#prediction#\n",
    "y_pred=model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###new prediction#\n",
    "my_text=\"I HAVE A DATE ON SUNDAY WITH WILL!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text=np.array([my_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I HAVE A DATE ON SUNDAY WITH WILL!!'], dtype='<U35')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(max_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40824829, 0.40824829, 0.40824829, 0.40824829, 0.40824829,\n",
       "        0.40824829]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-2ee7852b789d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "my_text=tfidf.fit_transform(my_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40824829, 0.40824829, 0.40824829, 0.40824829, 0.40824829,\n",
       "        0.40824829]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected axis -1 of input shape to have value 1510 but received input with shape (None, 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-bbb3d2a5f524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    457\u001b[0m                   \u001b[1;34m'  if your model does binary classification '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                   '  (e.g. if it uses a `sigmoid` last-layer activation).')\n\u001b[1;32m--> 459\u001b[1;33m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3357\u001b[1;33m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[0;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3277\u001b[0m           expand_composites=True)\n\u001b[0;32m   3278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3279\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected axis -1 of input shape to have value 1510 but received input with shape (None, 6)\n"
     ]
    }
   ],
   "source": [
    "model.predict_classes(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected axis -1 of input shape to have value 1510 but received input with shape (None, 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-bbb3d2a5f524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    457\u001b[0m                   \u001b[1;34m'  if your model does binary classification '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                   '  (e.g. if it uses a `sigmoid` last-layer activation).')\n\u001b[1;32m--> 459\u001b[1;33m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3357\u001b[1;33m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[0;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3277\u001b[0m           expand_composites=True)\n\u001b[0;32m   3278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3279\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected axis -1 of input shape to have value 1510 but received input with shape (None, 6)\n"
     ]
    }
   ],
   "source": [
    "model.predict_classes(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
